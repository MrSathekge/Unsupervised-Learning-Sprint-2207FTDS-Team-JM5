{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad3a7b78",
   "metadata": {},
   "source": [
    "# Challenge Description\n",
    "\n",
    "In today’s technology driven world, recommender systems are socially and economically critical for ensuring that individuals can make appropriate choices surrounding the content they engage with on a daily basis. One application where this is especially true surrounds movie content recommendations; where intelligent algorithms can help viewers find great titles from tens of thousands of options.\n",
    "\n",
    "…ever wondered how Netflix, Amazon Prime, Showmax, Disney and the likes somehow know what to recommend to you? \n",
    "\n",
    "<img src=\"imgs/header.png\" width=\"800\" />\n",
    "\n",
    "…it's not just a guess drawn out of the hat. There is an algorithm behind it.\n",
    "\n",
    "With this context, EDSA challenged us to construct a `recommendation algorithm` based on `content` or `collaborative filtering`, capable of accurately predicting how a user will `rate` a movie they have not yet viewed based on their historical preferences.\n",
    "\n",
    "**What value is achieved through building a functional recommender system?**\n",
    "\n",
    "Providing an accurate and robust solution to this challenge has immense economic potential, with users of the system being exposed to content they would like to view or purchase - generating revenue and platform affinity.\n",
    "<img src=\"imgs/recommendation-system.webp\" width=\"600\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52307d6f",
   "metadata": {},
   "source": [
    "# Dataset Description\n",
    "### Data Overview\n",
    "\n",
    "This dataset consists of several million 5-star ratings obtained from users of the online MovieLens movie recommendation service. The MovieLens dataset has long been used by industry and academic researchers to improve the performance of explicitly-based recommender systems, and now you get to as well!\n",
    "\n",
    "For this Predict, we'll be using a special version of the MovieLens dataset which has enriched with additional data, and resampled for fair evaluation purposes. \n",
    "\n",
    "### Source\n",
    "\n",
    "The data for the MovieLens dataset is maintained by the GroupLens research group in the Department of Computer Science and Engineering at the University of Minnesota. Additional movie content data was legally scraped from IMDB.\n",
    "\n",
    "### Supplied Files\n",
    "\n",
    "- genome_scores.csv - a score mapping the strength between movies and tag-related properties.\n",
    "- genome_tags.csv - user assigned tags for genome-related scores\n",
    "- imdb_data.csv - Additional movie metadata scraped from IMDB using the links.csv file.\n",
    "- links.csv - File providing a mapping between a MovieLens ID and associated IMDB and TMDB IDs.\n",
    "- sample_submission.csv - Sample of the submission format for the hackathon.\n",
    "- tags.csv - User assigned for the movies within the dataset.\n",
    "- test.csv - The test split of the dataset. Contains user and movie IDs with no rating data.\n",
    "- train.csv - The training split of the dataset. Contains user and movie IDs with associated rating data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbfdf14",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Loading Comet & Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Data Engineering</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Model Performance</a>\n",
    "\n",
    "<a href=#seven>7. Conclusion</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1640c833",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "### 1. Connecting Comet\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to import, and briefly discuss, the libraries that will be used to save the notebook version in comet. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679ca7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94afc93e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4b4be82",
   "metadata": {},
   "source": [
    "###  Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to import, and briefly discuss, the libraries that will be used throughout your analysis and modelling. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12cea485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3230e956",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Loading the data ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to load the data from the `train` file into a DataFrame. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d0058e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e46462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9bd8179",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "### 3. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Exploratory data analysis ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to perform an in-depth analysis of all the variables in the DataFrame. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9361a440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25615e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "992473f7",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "### 4. Data Engineering\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Data engineering ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to: clean the dataset, and possibly create new features - as identified in the EDA phase. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49291e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829014ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ccd3f5b",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "### 5. Modeling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Modeling ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to create one or more classification models that are able to accurately classify tweets as the per sentiment. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0882ea93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4a22ea0",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "### 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model performance ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to compare the relative performance of the various trained ML models on a holdout dataset and comment on what model is the best and why. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a35637f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa86bfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63071b2c",
   "metadata": {},
   "source": [
    " <a id=\"seven\"></a>\n",
    "### 1. Conclusion\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c496ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
